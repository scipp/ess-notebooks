{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing and reducing WFM imaging data with Scipp\n",
    "\n",
    "\n",
    "## How to start\n",
    "\n",
    "Before starting you must:\n",
    "\n",
    "- Have conda installed\n",
    "- `conda env create -f ess-notebooks-latest.yml python=3.7` . The yaml environment file is part of this repository.\n",
    "- fetch the data `git clone git@github.com:scipp/ess-notebooks-data.git` somewhere local \n",
    "- Generate the `dataconfig.py` file using `make_config.py` located in same directory as this notebook. In general, you simply need to point `make_config.py` to the root directory of data you cloned above. Refer to the help `make_config.py --help` for more information. \n",
    "\n",
    "## Experimental Summary\n",
    "\n",
    "This script has been developed to measure local strain $\\varepsilon$ defined as $\\varepsilon = \\Delta L/L_{0}$ in a FCC steel sample under elastic strain in a stress rig.\n",
    "The measurements were measured at V20, HZB, Berlin, in September 2018 by Peter Kadletz.\n",
    "\n",
    "$\\lambda = 2 d \\sin\\theta$, where $2\\theta = \\pi$ (transmission), edges characterise the Bragg condition and hence $\\lambda = 2 d$.\n",
    "Therefore strain is easily computed from the wavelength measurement of a Bragg edge directly, using un-loaded vs loaded experimental runs (and reference mesurements).\n",
    "\n",
    "The known Miller indices of the crystal structure (FCC) are used to predict the wavelength of the Bragg edges, which is bound by the reachable wavelength extents of the instrument.\n",
    "This provides an approximate region to apply a fit.\n",
    "A complement error function is used to fit each Bragg edge, and a refined centre location ($\\lambda$) for the edge is used in the strain measurement.\n",
    "Because each Bragg edge can be identified individually, one can determine anisotropic strain across the unit cell in the reachable crystallographic directions.\n",
    "\n",
    "<img src=\"IMG_2290.jpg\" width=\"500\" />\n",
    "\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipp as sc\n",
    "import scippneutron as sn\n",
    "from scipp import plot\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import ess.v20.imaging as imaging\n",
    "import ess.v20.imaging.operations as operations\n",
    "import ess.v20.wfm as wfm\n",
    "from ess.v20.wfm.beamline import choppers\n",
    "\n",
    "import dataconfig\n",
    "\n",
    "local_data_path = os.path.join('ess', 'v20', 'imaging',\n",
    "                               'gp2-stress-experiments')\n",
    "data_dir = os.path.join(dataconfig.data_root, local_data_path)\n",
    "instrument_file = os.path.join(data_dir, 'V20_Definition_GP2.xml')\n",
    "tofs_path = os.path.join(data_dir, 'GP2_Stress_time_values.txt')\n",
    "raw_data_dir = os.path.join(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Reduction\n",
    "\n",
    "## Load the data files and instrument geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_scale(folder_name, scale_factor):\n",
    "    to_load = os.path.join(raw_data_dir, folder_name)\n",
    "    variable = imaging.tiffs_to_variable(to_load, dtype=np.float32, with_variances=False)\n",
    "    variable *= scale_factor\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of pulses for each run, to scale data according to integration times\n",
    "pulse_number_reference = 1.0 / 770956\n",
    "pulse_number_sample = 1.0 / 1280381\n",
    "pulse_number_sample_elastic = 1.0 / 2416839\n",
    "pulse_number_sample_plastic = 1.0 / 2614343\n",
    "\n",
    "# Create Dataset\n",
    "ds = sc.Dataset()\n",
    "\n",
    "# Load time bins from 1D text file\n",
    "ds.coords[\"t\"] = sc.Variable(\n",
    "    [\"t\"],\n",
    "    unit=sc.units.us,\n",
    "    values=imaging.read_x_values(tofs_path,\n",
    "                                 skiprows=1,\n",
    "                                 usecols=1,\n",
    "                                 delimiter='\\t') * 1.0e3)\n",
    "\n",
    "# Load tiff stack\n",
    "ds[\"reference\"] = load_and_scale(folder_name=\"R825-open-beam\",\n",
    "                                 scale_factor=pulse_number_reference)\n",
    "ds[\"sample\"] = load_and_scale(folder_name=\"R825\",\n",
    "                              scale_factor=pulse_number_sample)\n",
    "ds[\"sample_elastic\"] = load_and_scale(\n",
    "    folder_name=\"R825-600-Mpa\", scale_factor=pulse_number_sample_elastic)\n",
    "\n",
    "# Instrument geometry\n",
    "geometry = sc.Dataset()\n",
    "sn.mantid.load_component_info(geometry, instrument_file)\n",
    "geom = sc.Dataset(coords={\"source_position\": geometry.coords[\"source_position\"]})\n",
    "geom.coords[\"position\"] = sc.reshape(geometry.coords['position'],\n",
    "                                     dims=['y', 'x'],\n",
    "                                     shape=tuple(ds[\"sample\"][\"t\",\n",
    "                                                              0].shape))\n",
    "geom.coords[\"x\"] = sc.geometry.x(geom.coords[\"position\"])[\"y\", 0]\n",
    "geom.coords[\"y\"] = sc.geometry.y(geom.coords[\"position\"])[\"x\", 0]\n",
    "ds = sc.merge(ds, geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ds[\"sample\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Converting time coordinate to TOF\n",
    "\n",
    "Use the instrument geometry and chopper cascade parameters to compute time-distance diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beamline = choppers()\n",
    "# Add the detector pixel positions\n",
    "beamline[\"position\"] = ds.coords[\"position\"] - ds.coords[\n",
    "    \"source_position\"] + sc.scalar(0.5 * np.sum(beamline[\"distance\"][\"chopper\", 0:2].values, axis=0),\n",
    "                 dtype=sc.dtype.vector_3_float64, unit=beamline[\"distance\"].unit)\n",
    "beamline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = wfm.get_frames(instrument=beamline, plot=True)\n",
    "frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume all pixels have the same frame boundaries, so we take the mean boundaries for each frame (this saves memory in the stitching step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in [\"left_edges\", \"right_edges\"]:\n",
    "    frames[key] = sc.mean(sc.mean(frames[key], 'x'), 'y')\n",
    "frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We overlay the frame locations onto a spectrum of integrated counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots()\n",
    "plot(sc.sum(sc.sum(ds[\"reference\"], 'x'), 'y'), ax=ax1)\n",
    "for i in range(frames.sizes[\"frame\"]):\n",
    "    ax1.axvspan(frames[\"left_edges\"][\"frame\", i].value,\n",
    "                frames[\"right_edges\"][\"frame\", i].value, color=\"C{}\".format(i), alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the sections in the original data using value-based slicing and shift the coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched = wfm.stitch(data=ds, dim=\"t\", frames=frames, plot=True)\n",
    "stitched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To stitch the data, we make a common container with a TOF axis spanning the entire range, and sum the counts from the different frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sc.sum(sc.sum(stitched, 'x'), 'y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop to relevant Tof section\n",
    "\n",
    "We take a subset of the Tof range which contains the Bragg edges of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tof_start = 9.0e3*sc.units.us\n",
    "tof_end = 2.75e4*sc.units.us\n",
    "stitched = stitched[\"tof\", tof_start:tof_end].copy()\n",
    "plot(sc.sum(sc.sum(stitched, 'x'), 'y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transmission Masking\n",
    "\n",
    "Divides the integrated sample counts with an open beam reference. Any values > masking threshold will be masked. The adj pixels step checks for random pixels which were left unmasked or masked with all their neighbours having the same mask value. These are forced to True or false depending on their neighbour value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated = sc.sum(stitched, 'tof')\n",
    "integrated /= integrated[\"reference\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masking_threshold = 0.80 * sc.units.one\n",
    "\n",
    "for key in [\"sample\", \"sample_elastic\"]:\n",
    "    mask = integrated[key].data > masking_threshold\n",
    "    # Apply some neighbour smoothing to the masks\n",
    "    mask = operations.mask_from_adj_pixels(mask)\n",
    "    stitched[key].masks[\"non-sample-region\"] = mask\n",
    "stitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sc.sum(stitched[\"sample\"], \"tof\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to wavelength\n",
    "\n",
    "Scipp's `neutron` submodule contains utilities specific to neutron science, and in particular unit conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength = sn.convert(stitched, origin=\"tof\", target=\"wavelength\", scatter=False)\n",
    "\n",
    "# Rebin to common wavelength axis\n",
    "edges = sc.array(dims=[\"wavelength\"],\n",
    "                       values=np.linspace(2.0, 5.5, 129), unit=sc.units.angstrom)\n",
    "wavelength = sc.rebin(wavelength, \"wavelength\", edges)\n",
    "\n",
    "wavelength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply mean filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in wavelength:\n",
    "    wavelength[key].data = operations.mean_from_adj_pixels(wavelength[key].data)\n",
    "plot(wavelength[\"sample\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other visualizations\n",
    "\n",
    "### Show difference between sample and elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(wavelength[\"sample\"] - wavelength[\"sample_elastic\"], vmin=-0.002, vmax=0.002, cmap=\"RdBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group detector pixels to increase signal to noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins=27\n",
    "grouped = operations.groupby2D(wavelength, nx_target=nbins, ny_target=nbins)\n",
    "for key, item in grouped.items():\n",
    "    item.masks[\"zero-counts\"] = item.data == 0.0*sc.units.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(grouped[\"sample\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize by open beam\n",
    "normalized = grouped / grouped[\"reference\"]\n",
    "del normalized[\"reference\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "replacement = sc.Variable(value=0.0, variance=0.0)\n",
    "kwargs = {\"nan\": replacement, \"posinf\": replacement, \"neginf\": replacement}\n",
    "for k in normalized.keys():\n",
    "    sc.nan_to_num(normalized[k].data, out=normalized[k].data, **kwargs)\n",
    "\n",
    "summed = sc.sum(sc.sum(normalized, 'x'), 'y')    \n",
    "plot(summed, grid=True, title='I/I0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bragg edge fitting\n",
    "\n",
    "We will first carry out Bragg-edge fitting on the sum of all counts in the sample.\n",
    "\n",
    "## Calculate expected Bragg edge positions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Braggedge_list(lattice_constant, miller_indices):\n",
    "    '''\n",
    "    :param miller-indices: like [(1,1,0),(2,0,0),...]\n",
    "    :type miller-indices: list of tuples\n",
    "    '''\n",
    "    coords = [str((h, k, l)) for h, k, l in miller_indices]\n",
    "    interplanar_distances = [\n",
    "        2. * lattice_constant / np.sqrt(h**2 + k**2 + l**2)\n",
    "        for h, k, l in miller_indices\n",
    "    ]\n",
    "\n",
    "    d = sc.DataArray(\n",
    "        sc.Variable(dims=[\"bragg-edge\"],\n",
    "                    values=np.array(interplanar_distances),\n",
    "                    unit=sc.units.angstrom))\n",
    "    d.coords[\"miller-indices\"] = sc.Variable(dims=[\"bragg-edge\"],\n",
    "                                             values=coords)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bragg edge position, in Angstrom, taken from COD entry 9008469\n",
    "FCC_a = 3.5\n",
    "\n",
    "# These miller indices for the given unit cell yield bragg edges\n",
    "# between the maximum and minimum wavelength range.\n",
    "indices_FCC = [(1, 1, 1), (2, 0, 0), (2, 2, 0), (3, 1, 1)]\n",
    "\n",
    "Bragg_edges_FCC = create_Braggedge_list(FCC_a, indices_FCC)\n",
    "sc.table(Bragg_edges_FCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the fitting (currently using Mantid under the hood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(Bragg_edges_FCC, reference, quiet=False):\n",
    "    \"\"\"\n",
    "    Fit a list of Bragg edges using Mantid.\n",
    "    \"\"\"\n",
    "\n",
    "    x_min_sides = [0.05, 0.1, 0.1, 0.05]\n",
    "    x_max_sides = [0.1, 0.05, 0.1, 0.1]\n",
    "    fit_list = []\n",
    "\n",
    "    for edge_index in range(Bragg_edges_FCC.shape[0]):\n",
    "\n",
    "        bragg_edge = Bragg_edges_FCC.coords[\"miller-indices\"][\"bragg-edge\",\n",
    "                                                              edge_index]\n",
    "\n",
    "        # Initial guess\n",
    "        xpos_guess = Bragg_edges_FCC[\"bragg-edge\", edge_index].value\n",
    "        x_min_fit = xpos_guess - xpos_guess * abs(x_min_sides[edge_index])\n",
    "        x_max_fit = xpos_guess + xpos_guess * abs(x_max_sides[edge_index])\n",
    "\n",
    "        if not quiet:\n",
    "            print(\n",
    "                \"Now fitting Bragg edge {} at {:.3f} A (between {:.3f} A and {:.3f} A) across image groups\"\n",
    "                .format(bragg_edge, xpos_guess, x_min_fit, x_max_fit))\n",
    "\n",
    "        # Call Mantid fitting\n",
    "        params_s, diff_s = sn.mantid.fit(\n",
    "            reference,\n",
    "            mantid_args={\n",
    "                'Function':\n",
    "                f'name=LinearBackground,A0={270},A1={-10};name=UserFunction,Formula=h*erf(a*(x-x0)),h={200},a={-11},x0={xpos_guess}',\n",
    "                'StartX': x_min_fit,\n",
    "                'EndX': x_max_fit\n",
    "            })\n",
    "\n",
    "        v_and_var_s = [\n",
    "            params_s.data['parameter', i]\n",
    "            for i in range(params_s['parameter', :].shape[0])\n",
    "        ]\n",
    "        params = dict(zip(params_s.coords[\"parameter\"].values, v_and_var_s))\n",
    "\n",
    "        fit_list.append(params)\n",
    "\n",
    "    return fit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = fit(Bragg_edges_FCC, reference=summed[\"sample\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "fig, ax = plt.subplots()\n",
    "summed[\"sample\"].plot(ax=ax)\n",
    "for i, f in enumerate(fit_params):\n",
    "    x = np.linspace(f['f1.x0'].value - 0.3, f['f1.x0'].value + 0.3, 100)\n",
    "    y=f['f1.h'].value*sp.special.erf(f['f1.a'].value*(x-f['f1.x0'].value)) + (f['f0.A0'].value + f['f0.A1'].value*x)\n",
    "    ax.plot(x, y, color=\"C{}\".format(i+1), label=Bragg_edges_FCC.coords['miller-indices'].values[i])\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a strain map\n",
    "\n",
    "We can create a strain map by fitting the Bragg edges inside each tile of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty container to receive the strain values\n",
    "strain_map = normalized[\"sample_elastic\"][\"wavelength\", 0] * (0.0 * sc.units.one)\n",
    "\n",
    "iprog = 0\n",
    "step = 5\n",
    "\n",
    "# Loop over all the tiles\n",
    "for j in range(nbins):\n",
    "    for i in range(nbins):\n",
    "\n",
    "        prog = int(100 * (i + j*nbins) / (nbins*nbins))\n",
    "        if prog % step == 0 and prog == iprog:\n",
    "            print(prog, \"% complete\")\n",
    "            iprog += step\n",
    "        \n",
    "        if sc.greater(sc.sum(normalized[\"sample_elastic\"]['y', j]['x', i], \"wavelength\").data,\n",
    "                      0.0*sc.units.one).value:\n",
    "            elastic_fit = fit(Bragg_edges_FCC,\n",
    "                                    reference=normalized[\"sample_elastic\"]['y', j]['x', i], quiet=True)\n",
    "            strain_map['y', j]['x', i] = 0.5 * (elastic_fit[0]['f1.x0'] - fit_params[0]['f1.x0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(strain_map, vmin=-0.02, vmax=0.02, cmap=\"RdBu\", title=\"Lattice strain $\\epsilon$ (1, 1, 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
