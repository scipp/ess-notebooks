{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lightweight-darwin",
   "metadata": {},
   "source": [
    "# Data reduction for Amor using `scipp`\n",
    "\n",
    "Herein, we will look in detail at the reduction of data collected from the Amor instrument using `scipp` ([scipp.github.io](https://scipp.github.io)), giving information about the data reduction steps used at Amor. \n",
    "All of the steps given here, are implemented in the `AmorData` class ([scipp.github.io/ess/instruments/amor/amor_data](https://scipp.github.io/ess/instruments/amor/amor_data.html)) and it is shown how easily they may be accessed from this [simple reduction notebook](https://scipp.github.io/ess-notebooks/reflectometry/amor_reduction.html).\n",
    "\n",
    "Let's start by importing the modules necessary for this notebook and loading the data, where [sample.nxs](https://github.com/scipp/ess-notebooks-data/raw/main/ess/amor/sample.nxs) is the experimental data file of interest and [reference.nxs](https://github.com/scipp/ess-notebooks-data/raw/main/ess/amor/references.nxs) is the reference measurement of the neutron supermirror."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dataconfig\n",
    "import numpy as np\n",
    "from scipy.special import erf\n",
    "import scipp as sc\n",
    "import scippneutron as scn\n",
    "from ess.reflectometry.data import ReflData\n",
    "from ess.reflectometry import HDM, G_ACC\n",
    "from ess.amor.amor_data import AmorData\n",
    "\n",
    "local_data_path = os.path.join('ess', 'amor')\n",
    "data_dir = os.path.join(dataconfig.data_root, local_data_path)\n",
    "data_file = os.path.join(data_dir, 'sample.nxs')\n",
    "reference_file = os.path.join(data_dir, 'reference.nxs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-amber",
   "metadata": {},
   "source": [
    "## Data Storage\n",
    "\n",
    "The data collected from the Amor instrument is written to a NeXus file, which can be read into `scipp` was follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scn.load_nexus(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-button",
   "metadata": {},
   "source": [
    "The data is stored in a binned structure, where each of the bin is a pixel on the detector containing each neutron event that was measured there. \n",
    "For convinence, we will store this `data` in the `ReflData` class, which assigns values of 1 for the variances of each event (following Poisson statistics), and enables easy visualisation of all of the neutron events. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "refl = ReflData(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "refl.data.events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-schedule",
   "metadata": {},
   "source": [
    "It is also possible to visualise the detector, with the neutron events shown in the relevant pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "scn.instrument_view(refl.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-jordan",
   "metadata": {},
   "source": [
    "## Time-of-flight correction\n",
    "\n",
    "The time-of-flight values present in the `refl` object above is taken from the `event_time_offset`, $t_{\\text{eto}}$.\n",
    "Therefore, it is necessary to account for an offset due to the pulse generation. \n",
    "This correction is performed by considering half of the reciprocal rotational velocity of the chopper, $\\tau$ and the phase offset between the chopper pulse and the time-of-flight $0$, $\\phi_{\\text{chopper}}$, \n",
    "\n",
    "$$\n",
    "t_{\\text{offset}} = \\tau \\phi_{\\text{chopper}}.\n",
    "$$\n",
    "\n",
    "The time-of-flight is then found as, \n",
    "\n",
    "$$\n",
    "t = [(t_{\\text{eto}} - t_{\\text{cut}} + \\tau) \\;\\text{mod}\\; \\tau] + t_{\\text{cut}} + t_{\\text{offset}},\n",
    "$$\n",
    "\n",
    "where, $\\text{mod}$ is the remainder between the two values and $t_{\\text{cut}}$ is found from the minimum wavelength, $\\lambda$, to be used. \n",
    "In order to perform this conversion, first we convert the time-of-flight coordinate in the event data to microseconds (this is for clarity, due to the commonality of the unit, though not strictly necessary). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_eto = sc.to_unit(refl.data.events.coords['tof'], 'us')\n",
    "t_eto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-medicine",
   "metadata": {},
   "source": [
    "First, $t_{\\text{offset}}$ can be found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "chopper_speed = 20 / 3 * 1e-6 / sc.units.us\n",
    "tau = sc.to_unit(1 / (2 * chopper_speed), 'us')\n",
    "chopper_phase = -8.0 * sc.units.deg\n",
    "t_offset = sc.to_unit(tau * chopper_phase / (180.0 * sc.units.deg), 'us')\n",
    "t_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-particle",
   "metadata": {},
   "source": [
    "And then $t_{\\text{cut}}$ from the minimum wavelength value, where `HDM` is the ratio of Planck's constant, $h$, to the neutron mass, $m_n$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_cut = 2.4 * sc.units.angstrom\n",
    "chopper_detector_distance = 19 * sc.units.m\n",
    "t_cut = sc.to_unit(wavelength_cut * chopper_detector_distance / HDM, 'us')\n",
    "t_cut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-fabric",
   "metadata": {},
   "source": [
    "The time-of-flight is then found, currently using the `np.remainder` functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_array = np.remainder((t_eto - t_cut + tau).values, tau.values)\n",
    "t = sc.Variable(\n",
    "    values = t_array, \n",
    "    unit=sc.units.us, \n",
    "    dims=['event'], \n",
    "    dtype=sc.dtype.float64) + t_cut + t_offset\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-amplifier",
   "metadata": {},
   "source": [
    "Having corrected the time-of-flight, this coordinate in the `refl` object can be overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "refl.data.events.coords['tof'] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-pierre",
   "metadata": {},
   "outputs": [],
   "source": [
    "refl.data.events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-stack",
   "metadata": {},
   "source": [
    "The corrected time-of-flight is now in the file, and it is possible to visualise a histogram of the values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_t = sc.max(refl.data.events.coords['tof'])\n",
    "min_t = sc.min(refl.data.events.coords['tof'])\n",
    "bins = sc.Variable(values=np.linspace(min_t.value, max_t.value, 100), \n",
    "                   unit=refl.data.events.coords['tof'].unit,\n",
    "                   dims=['tof'])\n",
    "sc.histogram(refl.event, bins).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-speaking",
   "metadata": {},
   "source": [
    "## Time-of-flight to wavelength conversion\n",
    "\n",
    "The time-of-flight has been determined, therefore it is now possible to convert the time-of-flight to wavelength, an important step in determining $q$. \n",
    "`scipp` includes built in functionality to perform this conversion based on the instrument geometry. \n",
    "However, the `source_position` must be modified to account for the fact that the pulse is defined by the chopper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "chopper_sample_distance=15.0 * sc.units.m\n",
    "refl.data.attrs[\"source_position\"] = sc.geometry.position(0.0 * sc.units.m, \n",
    "                                                          0.0 * sc.units.m, \n",
    "                                                          -chopper_sample_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-booth",
   "metadata": {},
   "source": [
    "This correction makes use of the definition of the sample position at $0, 0, 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "refl.data.attrs['sample_position']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-strength",
   "metadata": {},
   "source": [
    "With this correction in place, the `scippneutron.convert` function can be used to find the wavelength. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b887d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "refl.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-thirty",
   "metadata": {},
   "outputs": [],
   "source": [
    "refl.data = scn.convert(refl.data, origin='tof', target='wavelength', scatter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-lafayette",
   "metadata": {},
   "source": [
    "Here, this is performed such that the `'tof'` coordinate is lost, this is not the cause for the `AmorData` implementation. \n",
    "\n",
    "Similar to the time-of-flight, it is possible to visualise the $\\lambda$-values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-deputy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_w = sc.max(refl.event.coords['wavelength'])\n",
    "min_w = sc.min(refl.event.coords['wavelength'])\n",
    "bins = sc.Variable(values=np.linspace(min_w.value, max_w.value, 100), \n",
    "                   unit=refl.event.coords['wavelength'].unit,\n",
    "                   dims=['wavelength'])\n",
    "sc.histogram(refl.event, bins).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-garlic",
   "metadata": {},
   "source": [
    "## Theta calculation and gravity correction\n",
    "\n",
    "The Amor reflectometer scatters neutrons vertically in space from a horizontal scattering surface. \n",
    "Therefore, when the scattering angle, $\\theta$, is found, it is necessary to consider the effect that gravity will have on the neutron's trajectory. \n",
    "\n",
    "<center>\n",
    "    <img src='gravity.png' width=60%>\n",
    "    <i>\n",
    "        The effect of gravity for a neutron with a velocity of 20 ms<sup>-1</sup>; the solid blue line shows the trajectory of a neutron reflected from a surface under the influence of graivty, the dashed green line shows the trajectory without gravity if no correction, the solid orange line shows the true trajectory if the reflection were to occur with no gravity present.\n",
    "    </i>\n",
    "</center>\n",
    "\n",
    "The figure above shows the trajectory of a neutron reflecting from a sample and being detected on the detector (the blue line). \n",
    "Initially assuming that all of the neutron are detected at the point $(0, 0)$ (the influence of beam and sample width is [considered below](#Resolution-functions)). \n",
    "During the trajectory, the neutron is acted on by the force of gravity, leading to the parabolic motion shown. \n",
    "It is clear that if $\\theta$ were calculated without accounting for graivty (dashed green line), then the angle would be underestimated. \n",
    "\n",
    "The trajectory for the detected neutron can be found by considering the kinematic equations of motion. \n",
    "The time taken for the neutron to travel from $z=z_0$ to $z=z_d$ is, \n",
    "\n",
    "$$\n",
    "t_d = \\frac{z_d - z_0}{v_z}, \n",
    "$$\n",
    "\n",
    "where, $v_z$ is the velocity of the neutron in the z-dimension. \n",
    "It is assumed that the velocity in this dimension is the main component of the total velocity and that this doesn't change over time. \n",
    "Therefore, we can calculate $v_z$ from the neutron's wavelength as, \n",
    "\n",
    "$$\n",
    "v_z = \\frac{h}{m_n\\lambda}.\n",
    "$$\n",
    "\n",
    "This can be found as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "refl.data.events.coords[\"velocity\"] = sc.to_unit(HDM / refl.data.events.coords['wavelength'], 'm/s')\n",
    "refl.data.events.coords[\"velocity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-capacity",
   "metadata": {},
   "source": [
    "It is assumed that the parabolic motion does not reach a maximum before the neutron is incident on the detector. \n",
    "Therefore, the velocity in the $y$-dimension at the time of reflection can be found, \n",
    "\n",
    "$$\n",
    "v_y(0) = \\frac{y_d - y_0 - 0.5 a t_d^2}{t_d},\n",
    "$$\n",
    "\n",
    "where $y_0$ is the initial position of the neutron, $y_0 = 0$, and $a$ is the acceleration due to gravity, $a = -g = 9.80665\\;\\text{ms}^{-2}$. \n",
    "Using this, the $y$-position of the neutron can be found at any time, $t$, \n",
    "\n",
    "$$\n",
    "y(t) = y_0 + v_y(0)t + 0.5 a t^2, \n",
    "$$\n",
    "\n",
    "or any $z$-position (with $v_y(0)$ expanded), \n",
    "\n",
    "$$\n",
    "y(z) = y_0 + \\Bigg[(z - z_0) \\bigg(-\\frac{a (z_d - z_0)^2}{2v_z^2} - y_0 + y_d\\bigg)\\Bigg]\\frac{1}{z_d - z_0} + \\frac{a (z - z_0)^2}{2v_z^2}.\n",
    "$$\n",
    "\n",
    "The derivative of this with respect to $z$ can then be found, \n",
    "\n",
    "$$\n",
    "y'(z) = \\bigg(\\frac{-a(z_d-z_0)^2}{2v_z^2}-y_0 + y_d\\bigg)\\frac{1}{z_d-z_0} + \\frac{a(z-z_0)}{v_z^2}, \n",
    "$$ \n",
    "\n",
    "This can be simplied when $z=z_0$ to, \n",
    "\n",
    "$$\n",
    "y'(z_0) = \\frac{-a (z_d-z_0)}{2v_z^2} + \\frac{y_d-y_0}{z_d-z_0}.\n",
    "$$\n",
    "\n",
    "From which $\\theta$ can be found,\n",
    "\n",
    "$$\n",
    "\\theta = -\\omega + \\tan^{-1}\\bigg(\\frac{y'(z_0)z_d + y_0 - y'(z_0)z_0}{z_d}\\bigg),\n",
    "$$\n",
    "\n",
    "where, $\\omega$ is the angle of the sample relative to the laboratory horizon. \n",
    "\n",
    "We can show this in action, first by defining a function for the derivative above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_dash0(velocity, z_origin, y_origin, z_measured, y_measured):\n",
    "    \"\"\"\n",
    "    Evaluation of the first dervative of the kinematic equations for for the trajectory of a neutron reflected from a surface.\n",
    "\n",
    "    Args:\n",
    "        velocity (:py:class:`scipp._scipp.core.VariableView`): Neutron velocity.\n",
    "        z_origin (:py:class:`scipp._scipp.core.Variable`): The z-origin position for the reflected neutron.\n",
    "        y_origin (:py:class:`scipp._scipp.core.Variable`): The y-origin position for the reflected neutron.\n",
    "        z_measured (:py:class:`scipp._scipp.core.Variable`): The z-measured position for the reflected neutron.\n",
    "        y_measured (:py:class:`scipp._scipp.core.Variable`): The y-measured position for the reflected neutron.\n",
    "\n",
    "    Returns:\n",
    "        (:py:class:`scipp._scipp.core.VariableView`): The gradient of the trajectory of the neutron at the origin position.\n",
    "    \"\"\"\n",
    "    velocity2 = velocity * velocity\n",
    "    z_diff = z_measured - z_origin\n",
    "    y_diff = y_measured - y_origin\n",
    "    return -0.5 * sc.norm(G_ACC) * z_diff / velocity2 + y_diff / z_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-boutique",
   "metadata": {},
   "source": [
    "The angle is found by evaluating the position of each pixel with respect to the sample position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_measured = refl.data.coords['position'].fields.y\n",
    "z_measured = refl.data.coords['position'].fields.z\n",
    "y_origin = refl.data.coords['sample_position'].fields.y\n",
    "z_origin = refl.data.coords['sample_position'].fields.z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-procedure",
   "metadata": {},
   "source": [
    "The gradient and hence the angle can then be found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dash = y_dash0(refl.data.bins.coords[\"velocity\"], z_origin, y_origin, z_measured, y_measured)\n",
    "intercept = y_origin - y_dash * z_origin\n",
    "y_true = z_measured * y_dash + intercept\n",
    "angle = sc.to_unit(sc.atan(y_true / z_measured).bins.constituents[\"data\"], 'deg')\n",
    "angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-filter",
   "metadata": {},
   "source": [
    "The value of $\\theta$ can then be found by accounting for the sample angle, $\\omega$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = 0.0 * sc.units.deg\n",
    "refl.data.events.coords['theta'] = -omega + angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-domain",
   "metadata": {},
   "source": [
    "This can be visualised similar to the wavelength and time-of-flight, or as a two-dimensional histogram of the intensity as a function of $\\lambda$/$\\theta$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_w = sc.max(refl.data.events.coords['wavelength'])\n",
    "min_w = sc.min(refl.data.events.coords['wavelength'])\n",
    "bins_w = sc.Variable(values=np.linspace(min_w.value, max_w.value, 50), \n",
    "                   unit=refl.event.coords['wavelength'].unit,\n",
    "                   dims=['wavelength'])\n",
    "max_t = sc.max(refl.data.events.coords['theta'])\n",
    "min_t = sc.min(refl.data.events.coords['theta'])\n",
    "bins_t = sc.Variable(values=np.linspace(min_t.value, max_t.value, 50), \n",
    "                   unit=refl.event.coords['theta'].unit,\n",
    "                   dims=['theta'])\n",
    "sc.bin(refl.event, [bins_t, bins_w]).bins.sum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-reset",
   "metadata": {},
   "source": [
    "## Determination of $q_z$-vector\n",
    "\n",
    "The $\\lambda$ and $\\theta$ can be brought together to calculate the the wavevector, $q_z$, \n",
    "\n",
    "$$\n",
    "q_z = \\frac{4\\pi \\sin{\\theta}}{\\lambda}.\n",
    "$$\n",
    "\n",
    "This is shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "refl.data.events.coords['qz'] = 4. * np.pi * sc.sin(\n",
    "    refl.data.events.coords['theta']) / refl.data.events.coords['wavelength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "refl.data.events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-replacement",
   "metadata": {},
   "source": [
    "We can then investigate the intensity as a function of $q_z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_q = 0.08 * sc.Unit('1/angstrom')\n",
    "min_q = 0.008 * sc.Unit('1/angstrom')\n",
    "bins_q = sc.Variable(values=np.linspace(min_q.value, max_q.value, 200), \n",
    "                   unit=refl.event.coords['qz'].unit,\n",
    "                   dims=['qz'])\n",
    "sc.histogram(refl.event, bins_q).plot(norm='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-authorization",
   "metadata": {},
   "source": [
    "## Illumination correction\n",
    "\n",
    "The above intensity as a function of $q_z$ fails to account for the difference in illumination as a function of $\\theta$. \n",
    "This is because the size of the beam which illuminates the sample decreases with increasing $\\theta$. \n",
    "\n",
    "<center>\n",
    "    <img src='beam_size.png' width=60%>\n",
    "    <i>\n",
    "        The effect of $\\theta$ on the beam size on the sample (blue line) and the resulting scale factor where the size of the sample is considered (orange line); where the beam size is 1 cm and the sample is 10 cm.\n",
    "    </i>\n",
    "</center>\n",
    "\n",
    "Using the assumption that the beam size describes the full width at half maximum of the beam, the following function can be used to determine the scale factor necessary to account for the illumination variation as a function of $\\theta$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def illumination_correction(beam_size, sample_size, theta):\n",
    "    \"\"\"\n",
    "    The factor by which the intensity should be multiplied to account for the\n",
    "    scattering geometry, where the beam is Gaussian in shape.\n",
    "\n",
    "    Args:\n",
    "        beam_size (:py:class:`scipp._scipp.core.Variable`): Width of incident beam.\n",
    "        sample_size (:py:class:`scipp._scipp.core.Variable`): Width of sample in the dimension of the beam.\n",
    "        theta (:py:class:`scipp._scipp.core.Variable`): Incident angle.\n",
    "\n",
    "    Returns:\n",
    "        (:py:class:`scipp._scipp.core.Variable`): Correction factor.\n",
    "    \"\"\"\n",
    "    beam_on_sample = beam_size / sc.sin(theta)\n",
    "    fwhm_to_std = 2 * np.sqrt(2 * np.log(2))\n",
    "    scale_factor = erf((sample_size / beam_on_sample * fwhm_to_std).values)\n",
    "    return sc.Variable(values=scale_factor, dims=theta.dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-dispatch",
   "metadata": {},
   "source": [
    "This illumination correction scale factor is applied to each event as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-darkness",
   "metadata": {},
   "outputs": [],
   "source": [
    "refl.data.events.data /= illumination_correction(\n",
    "    1 * sc.Unit('mm'), 10 * sc.Unit('mm'), refl.data.events.coords['theta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "refl.data.events.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-nursery",
   "metadata": {},
   "source": [
    "We can then show the reflected intensity as a function of $q_z$ as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_q = 0.08 * sc.Unit('1/angstrom')\n",
    "min_q = 0.008 * sc.Unit('1/angstrom')\n",
    "bins_q = sc.Variable(values=np.linspace(min_q.value, max_q.value, 200), \n",
    "                   unit=refl.event.coords['qz'].unit,\n",
    "                   dims=['qz'])\n",
    "sc.histogram(refl.event, bins_q).plot(norm='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-trouble",
   "metadata": {},
   "source": [
    "# Resolution functions\n",
    "\n",
    "The resolution function at Amor consists of three components:\n",
    "\n",
    "- $\\sigma \\lambda/\\lambda$: this is due to the double-blind chopper and depends on the distance between the two choppers, $d_{CC}$, and the distance from the second chopper to the detector $d_{CD}$, \n",
    "\n",
    "$$\n",
    "\\frac{\\sigma \\lambda}{\\lambda} = \\frac{d_{CC}}{2d_{CD}\\sqrt{2\\ln2}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "chopper_chopper_distance=0.49 * sc.units.m\n",
    "refl.data.attrs[\"sigma_lambda_by_lambda\"] = chopper_chopper_distance / (\n",
    "    refl.data.coords[\"position\"].fields.z - refl.data.coords[\"source_position\"].fields.z)\n",
    "refl.data.attrs[\"sigma_lambda_by_lambda\"] /= 2 * np.sqrt(2 * np.log(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4141c3",
   "metadata": {},
   "source": [
    "- $\\sigma \\gamma/\\theta$: this is to account for the spatial resolution of the detector pixels, which have a FWHM of $\\Delta z \\approx 2.5\\;\\text{mm}$ and the sample to detector distance, $d_{SD}$, \n",
    "\n",
    "$$\n",
    "\\frac{\\sigma \\gamma}{\\theta} = \\frac{1}{2\\theta\\sqrt{2\\ln2}}\\arctan{\\frac{\\Delta z}{d_{SD}}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4197ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_resolution = 0.0025 * sc.units.m\n",
    "fwhm = sc.to_unit(\n",
    "    sc.atan(\n",
    "        spatial_resolution / (\n",
    "                refl.data.coords[\"position\"].fields.z - \n",
    "                refl.data.coords[\"source_position\"].fields.z)),\"deg\",)\n",
    "sigma_gamma = fwhm / (2 * np.sqrt(2 * np.log(2)))\n",
    "refl.data.attrs[\"sigma_gamma_by_theta\"] = sigma_gamma / refl.data.bins.coords['theta']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab315161",
   "metadata": {},
   "source": [
    "- $\\sigma \\theta/\\theta$: finally, this accounts for the width of the beam on the sample or the size of the sample (which ever is smaller), the FWHM is the range of possible $\\theta$-values, accounting for the gravity correction discussed above and the sample/beam geometry,\n",
    "\n",
    "$$\n",
    "\\frac{\\sigma\\theta}{\\theta} = \\frac{1}{2\\sqrt{2\\ln2}}\\frac{\\theta_{\\text{max}} - \\theta_{\\text{min}}}{\\theta_{\\text{mid}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_size = 0.001 * sc.units.m\n",
    "sample_size = 0.5 * sc.units.m\n",
    "beam_on_sample = beam_size / sc.sin(refl.data.bins.coords['theta'])\n",
    "half_beam_on_sample = (beam_on_sample / 2.0)\n",
    "offset_positive = sc.geometry.position(\n",
    "    refl.data.coords[\"sample_position\"].fields.x, \n",
    "    refl.data.coords[\"sample_position\"].fields.y, \n",
    "    refl.data.coords[\"sample_position\"].fields.z + half_beam_on_sample)\n",
    "offset_negative = sc.geometry.position(\n",
    "    refl.data.coords[\"sample_position\"].fields.x, \n",
    "    refl.data.coords[\"sample_position\"].fields.y, \n",
    "    refl.data.coords[\"sample_position\"].fields.z - half_beam_on_sample)\n",
    "y_measured = refl.data.coords[\"position\"].fields.y\n",
    "z_measured = refl.data.coords[\"position\"].fields.z\n",
    "z_origin = offset_positive.fields.z\n",
    "y_origin = offset_positive.fields.y\n",
    "y_dash = y_dash0(refl.data.bins.coords[\"velocity\"], z_origin, y_origin, z_measured, y_measured)\n",
    "intercept = y_origin - y_dash * z_origin\n",
    "y_true = z_measured * y_dash + intercept\n",
    "angle_max = sc.to_unit(sc.atan(y_true / z_measured), 'deg')\n",
    "z_origin = offset_negative.fields.z\n",
    "y_origin = offset_negative.fields.y\n",
    "y_dash = y_dash0(refl.data.bins.coords[\"velocity\"], z_origin, y_origin, z_measured, y_measured)\n",
    "intercept = y_origin - y_dash * z_origin\n",
    "y_true = z_measured * y_dash + intercept\n",
    "angle_min = sc.to_unit(sc.atan(y_true / z_measured), 'deg')\n",
    "fwhm_to_std = 2 * np.sqrt(2 * np.log(2))\n",
    "sigma_theta_position = (angle_max - angle_min) / fwhm_to_std\n",
    "refl.data.attrs[\"sigma_theta_by_theta\"] = sigma_theta_position / refl.data.bins.coords['theta']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f317df7a",
   "metadata": {},
   "source": [
    "These three contributors to the resolution function are combined to give the total resolution function, \n",
    "\n",
    "$$\n",
    "\\frac{\\sigma q_z}{q_z} = \\sqrt{\\bigg(\\frac{\\sigma\\lambda}{\\lambda}\\bigg)^2+\\bigg(\\frac{\\sigma\\gamma}{\\theta}\\bigg)^2+\\bigg(\\frac{\\sigma\\theta}{\\theta}\\bigg)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88b4445",
   "metadata": {},
   "outputs": [],
   "source": [
    "refl.data.events.attrs['sigma_q_by_q'] = sc.sqrt(\n",
    "    refl.data.attrs['sigma_lambda_by_lambda'] * refl.data.attrs['sigma_lambda_by_lambda']\n",
    "    + refl.data.attrs['sigma_gamma_by_theta'] * refl.data.attrs['sigma_gamma_by_theta']\n",
    "    + refl.data.attrs[\"sigma_theta_by_theta\"] * refl.data.attrs[\"sigma_theta_by_theta\"]).bins.constituents['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b516044b",
   "metadata": {},
   "source": [
    "## Normalisation\n",
    "\n",
    "The above steps are performed both on the sample of interest and a reference supermirror, using the `AmorData` class, thus enabling normalisation to be achieved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb7ea86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = AmorData(data_file)\n",
    "reference = AmorData(reference_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c7847",
   "metadata": {},
   "source": [
    "These result in the plots shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52bca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.histogram(sample.data.events, bins_q).plot(norm='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cd7add",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.histogram(reference.data.events, bins_q).plot(norm='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6599f4ac",
   "metadata": {},
   "source": [
    "The specification of the supermirror defines the normalisation that is used for it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_value = 5\n",
    "supermirror_critical_edge = (0.022) * sc.Unit('1/angstrom')\n",
    "supermirror_max_q = m_value * supermirror_critical_edge\n",
    "supermirror_alpha = 0.25 / 0.088\n",
    "normalisation = sc.ones(dims=['event'], shape=reference.data.events.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b648c0a2",
   "metadata": {},
   "source": [
    "The data array is first masked at values greater than the upper limit of the supermirror. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46e1c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference.data.events.masks['normalisation'] = reference.data.events.coords['qz'] >= supermirror_max_q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241ab30c",
   "metadata": {},
   "source": [
    "The value of the $q$-dependent normalisation, $n(q)$, is then defined as such that $n(q)=1$ for values of $q$ less then the critical edge of the supermirror and for values between this and the supermirror maximum the normalisation is, \n",
    "\n",
    "$$ n(q) = \\frac{1}{1 - \\alpha(q - c_{\\text{sm}})}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa04f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalisation.values[reference.data.events.coords['qz'].values < supermirror_max_q.value] = 1 / (\n",
    "    1.0 - (supermirror_alpha) * (\n",
    "        reference.data.events.coords['qz'].values[\n",
    "            reference.data.events.coords['qz'].values < supermirror_max_q.value] - supermirror_critical_edge.value))\n",
    "normalisation.values[reference.data.events.coords['qz'].values <supermirror_critical_edge.value] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701ecc62",
   "metadata": {},
   "source": [
    "Applying this normalisation to the reference measurement data will return the neutron intensity as a function of $q$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e0f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference.data.bins.constituents['data'].data = reference.data.events.data / normalisation.astype(sc.dtype.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c1a9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.histogram(reference.data.events, bins_q).plot(norm='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93efc286",
   "metadata": {},
   "source": [
    "Binning this normalised description on the neutron intensity and the sample measurement in the same $q$-values allows the normalisation to be applied to the sample (note that scaling between these to measurements to account for counting time may be necessary). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbc6609",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_sample = sc.histogram(sample.data.events, bins_q)\n",
    "binned_reference = sc.histogram(reference.data.events, bins_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b4d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_sample = binned_sample / binned_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4e8e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_sample.plot(norm='log')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
